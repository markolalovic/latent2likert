@misc{mcnamara2024teaching,
      title={Teaching modeling in introductory statistics: A comparison of formula and tidyverse syntaxes}, 
      author={Amelia McNamara},
      year={2024},
      eprint={2201.12960},
      archivePrefix={arXiv},
      primaryClass={stat.OT}
}

@misc{psych,
      title = {psych: Procedures for Psychological, Psychometric, and Personality Research},
      author = {William Revelle},
      organization = {Northwestern University},
      address = {Evanston, Illinois},
      year = {2024},
      note = {R package version 2.4.3},
      url = {https://CRAN.R-project.org/package=psych},
}

@inproceedings{catlett1991,
author = {Catlett, J.},
title = {On changing continuous attributes into ordered discrete attributes},
year = {1991},
isbn = {354053816X},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/BFb0017012},
doi = {10.1007/BFb0017012},
abstract = {The large real-world datasets now commonly tackled by machine learning algorithms are often described in terms of attributes whose values are real numbers on some continuous interval, rather than being taken from a small number of discrete values. Many algorithms are able to handle continuous attributes, but learning requires far more CPU time than for a corresponding task with discrete attributes. This paper describes how continuous attributes can be converted economically into ordered discrete attributes before being given to the learning system. Experimental results from a wide variety of domains suggest this change of representation does not often result in a significant loss of accuracy (in fact it sometimes significantly improves accuracy), but offers large reductions in learning time, typically more than a factor of 10 in domains with a large number of continuous attributes.},
booktitle = {Proceedings of the 5th European Conference on European Working Session on Learning},
pages = {164–178},
numpages = {15},
keywords = {discretisation, empirical concept learning, induction of decision trees},
location = {Porto, Portugal},
series = {EWSL'91}
}

@article{wu2017,
author = {Huiping Wu and Shing-On Leung},
title = {Can Likert Scales be Treated as Interval Scales?—A Simulation Study},
journal = {Journal of Social Service Research},
volume = {43},
number = {4},
pages = {527-532},
year = {2017},
publisher = {Routledge},
doi = {10.1080/01488376.2017.1329775},
URL = {https://doi.org/10.1080/01488376.2017.1329775},
eprint = {https://doi.org/10.1080/01488376.2017.1329775}
}

@article{velicer2000,
  title={Construct explication through factor or component analysis: A review and evaluation of alternative procedures for determining the number of factors or components},
  author={Velicer, Wayne F and Eaton, Cheryl A and Fava, Joseph L},
  journal={Problems and solutions in human assessment: Honoring Douglas N. Jackson at seventy},
  pages={41--71},
  year={2000},
  publisher={Springer}
}

@article{cho2009,
author = {Sun-Joo Cho and Feiming Li and Deborah Bandalos},
title ={Accuracy of the Parallel Analysis Procedure With Polychoric Correlations},
journal = {Educational and Psychological Measurement},
volume = {69},
number = {5},
pages = {748-759},
year = {2009},
doi = {10.1177/0013164409332229},
URL = {https://doi.org/10.1177/0013164409332229},
eprint = {https://doi.org/10.1177/0013164409332229},
abstract = { The purpose of this study was to investigate the application of the parallel analysis (PA) method for choosing the number of factors in component analysis for situations in which data are dichotomous or ordinal. Although polychoric correlations are sometimes used as input for component analyses, the random data matrices generated for use in PA typically consist of Pearson correlations. In this study, the authors matched the type of random data matrix to the type of input matrix. Analyses were conducted on both polychoric and Pearson correlation matrices, and random matrices of the same type (polychoric or Pearson) were generated for the PA procedure. PA based on random Pearson correlations was found to perform at least as well as PA based on random polychoric correlations, for nearly all of the conditions studied. }
}

@misc{genz2020,
      author = {Genz, Alan and Bretz, Frank and Miwa, Tetsuhisa and Mi, Xuefei and Leisch, Friedrich and Scheipl, Fabian and Hothorn, Torsten},
      title  = {mvtnorm: Multivariate Normal and t Distributions},
      year   = {2020},
      url    = {https://cran.r-project.org/package=mvtnorm}
}

@misc{azzalini2023,
      author = {Azzalini A. Azzalini},
      title = {sn: The skew-normal and related distributions such as the skew-$t$},
      address = {Universita degli Studi di Padova, Italia},
      year = {2023},
      url = {https://cran.r-project.org/package=sn}
}

@misc{rinker2018,
      title = {wakefield: Generate Random Data},
      author = {Tyler W. Rinker},
      address = {Buffalo, New York},
      note = {version 0.3.3},
      year = {2018},
      url = {https://github.com/trinker/wakefield},
}

@misc{winzar2022,
      title = {LikertMakeR: Synthesise and correlate rating-scale data with predefined first & second moments},
      author = {Hume Winzar},
      abstract = {LikertMakeR synthesises Likert scale and related rating-scale data with predefined means and standard deviations, and optionally correlates these vectors to fit a predefined correlation matrix.},
      journal = {The Comprehensive R Archive Network (CRAN)},
      month = {12},
      year = {2022},
      url = {https://CRAN.R-project.org/package=LikertMakeR},
}

@article{touloumis2016,
    title = {Simulating Correlated Binary and Multinomial Responses under Marginal Model Specification: The SimCorMultRes Package},
    author = {Anestis Touloumis},
    year = {2016},
    journal = {The R Journal},
    volume = {8},
    number = {2},
    note = {R package version 1.9.0},
    pages = {79-91},
    url = {https://journal.r-project.org/archive/2016/RJ-2016-034/index.html},
}

@article{arnulf2018,
author = {Jan Ketil Arnulf and Kai R. Larsen and Øyvind L. Martinsen},
title ={Respondent Robotics: Simulating Responses to Likert-Scale Survey Items},
journal = {Sage Open},
volume = {8},
number = {1},
pages = {2158244018764803},
year = {2018},
doi = {10.1177/2158244018764803},
URL = {https://doi.org/10.1177/2158244018764803},
eprint = {https://doi.org/10.1177/2158244018764803},
abstract = { The semantic theory of survey responses (STSR) proposes that the prime source of statistical covariance in survey data is the degree of semantic similarity (overlap of meaning) among the items of the survey. Because semantic structures are possible to estimate using digital text algorithms, it is possible to predict the response structures of Likert-type scales a priori. The present study applies STSR in an experimental way by computing real survey responses using such semantic information. A sample of 153 randomly chosen respondents to the Multifactor Leadership Questionnaire (MLQ) was used as target. We developed an algorithm based on unfolding theory, where data from digital text analysis of the survey items served as input. Upon deleting progressive numbers (from 20\%-95\%) of the real responses, we let the algorithm replace these with simulated ones, and then compared the simulated datasets with the real ones. The simulated scores displayed sum score levels, alphas, and factor structures highly resembling their real origins even if up to 86\% were simulated. In contrast, this was not the case when the same algorithm was operating without access to semantic information. The procedure was briefly repeated on a different measurement instrument and a different sample. This not only yielded similar results but also pointed to need for further theoretical and practical developments. Our study opens for experimental research on the effect of semantics on survey responses using computational procedures. }
}

@article{chalmers2012,
    title = {{mirt}: A Multidimensional Item Response Theory Package
      for the {R} Environment},
    author = {R. Philip Chalmers},
    journal = {Journal of Statistical Software},
    year = {2012},
    volume = {48},
    number = {6},
    pages = {1--29},
    doi = {10.18637/jss.v048.i06},
}

@article{boari2015,
	author = {Giuseppe Boari and Marta Nai Ruscone},
	title = {A procedure simulating Likert scale item responses},
	journal = {Electronic Journal of Applied Statistical Analysis},
	volume = {8},
	number = {3},
	year = {2015},
	keywords = {Likert scale, Continuous variables discretization},
	abstract = {Data collected during a survey by means of a questionnaires are, in general, expressed with references to a Likert type scale, giving rise to non-metric data (ordinal categorical). However most of the statistocal procedures used to analyze survey data (for example FA or SEM) required at list interval scale measures, that may be obtained by using proper scaling procedures. In order to compare by simulation, the quantification thecniques most commonly used in the literature we consider necessary to achieve in advance an appropriate algorithm that best reproduces the discretization process followed by the respondents to the Likert questionnaire items. Accordingly, we propose a discretization procedures that, starting from a continuous random variables, describing all possible individual responses to a given stimulus, generates the corresponding categories, chosen among finite sets of integer values.},
	issn = {2070-5948},	
	url = {http://siba-ese.unisalento.it/index.php/ejasa/article/view/14747}
}


  
